{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import argparse\n",
    "import re\n",
    "import pickle\n",
    "from datetime import timedelta,datetime\n",
    "import google.oauth2.credentials\n",
    "import google_auth_oauthlib.flow as fl\n",
    "from googleapiclient.discovery import build\n",
    "from google.auth.transport.requests import Request\n",
    "from googleapiclient.errors import HttpError\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loding Credentials from File...\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('token.pickle'):\n",
    "    print('Loding Credentials from File...')\n",
    "    with open('token.pickle','rb') as token:\n",
    "        credentials=pickle.load(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refereshing access token...\n"
     ]
    }
   ],
   "source": [
    "if not credentials or not credentials.valid:\n",
    "        if credentials and credentials.expired and credentials.refresh_token:\n",
    "            print('Refereshing access token...')\n",
    "            credentials.refresh(Request())\n",
    "        else:\n",
    "            print('Fetching New Tokens...')\n",
    "            flow=fl.InstalledAppFlow.from_client_secrets_file('client_secret.json',scopes=['https://www.googleapis.com/auth/youtube.readonly'])\n",
    "            flow.run_local_server(port=8080, prompt='consent',authorization_prompt_message='')\n",
    "            credentials=flow.credentials\n",
    "        \n",
    "            with open('token.pickle','wb') as f:\n",
    "                print('Saving credentials for future use...')\n",
    "                pickle.dump(credentials,f)\n",
    "    \n",
    "        #credentials=flow.credentials\n",
    "    #print(credentials.to_json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube=build(\"youtube\",\"v3\",credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pulling all the playlists for my channel\n",
    "\n",
    "channel_id='UC-B_ggoiilgcbihS-GYBnIA'\n",
    "\n",
    "playlist_list=youtube.playlists().list(\n",
    "    part='contentDetails,id,snippet',\n",
    "    channelId=channel_id,\n",
    "    maxResults=25\n",
    "    )\n",
    "playlist_lists=playlist_list.execute()\n",
    "\n",
    "lst=[]\n",
    "for item in playlist_lists['items']:\n",
    "    lst.append({'playlist_id':item['id'],'playlist_name':item['snippet']['title'],'no_of_videos':item['contentDetails']['itemCount']})\n",
    "\n",
    "df=pd.DataFrame(lst)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling the necessary data for analysis purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_id='PL_wgt95pDQnwywGe6nd7C4-Np1IIFKCgD'\n",
    "\n",
    "vid_ids=[]\n",
    "nextpagetoken=None\n",
    "\n",
    "while True:\n",
    "    playlist_vid=youtube.playlistItems().list(\n",
    "        part='contentDetails,snippet',\n",
    "        playlistId=playlist_id,\n",
    "        maxResults=50,\n",
    "        pageToken=nextpagetoken\n",
    "        )\n",
    "    playlist_vids=playlist_vid.execute()\n",
    "\n",
    "    for item in playlist_vids['items']:\n",
    "        vid_ids.append({\n",
    "                            'video_id':item['contentDetails']['videoId'],\n",
    "                            'publisheddate':item.get('contentDetails',{}).get('videoPublishedAt',{}),\n",
    "                            'video_title':item['snippet']['title'],\n",
    "                            'videoOwnerChannelTitle':item.get('snippet',{}).get('videoOwnerChannelTitle',{}),\n",
    "                            'thumbnail':item.get('snippet',{}).get('thumbnails',{}).get('medium',{}).get('url',{})\n",
    "                        })\n",
    "    \n",
    "    nextpagetoken=playlist_vids.get('nextPageToken')\n",
    "    \n",
    "    if not nextpagetoken:\n",
    "        break\n",
    "    \n",
    "\n",
    "df2=pd.DataFrame(vid_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(447, 5)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 50\n",
    "videos = []\n",
    "music_category = []\n",
    "\n",
    "for i in range(0, len(vid_ids), chunk_size):\n",
    "    chunk = vid_ids[i:i + chunk_size]\n",
    "    video_ids = ','.join(item['video_id'] for item in chunk)\n",
    "\n",
    "    vid_request = youtube.videos().list(\n",
    "        part='statistics,contentDetails,snippet,topicDetails',\n",
    "        id=video_ids\n",
    "    )\n",
    "    vid_response = vid_request.execute()\n",
    "\n",
    "    for item in vid_response['items']:\n",
    "        vid_views = item['statistics']['viewCount']\n",
    "        vid_like_count = item.get('statistics',{}).get('likeCount',0)\n",
    "        vid_comment_count = item.get('statistics').get('commentCount',0)\n",
    "        video_id = item['id']\n",
    "        yt_link = f'https://youtu.be/{video_id}'\n",
    "        category_id = item['snippet']['categoryId']\n",
    "        categories = item.get('topicDetails', {}).get('topicCategories', [])\n",
    "        category_value = list(set(category.split('/')[-1] for category in categories))\n",
    "        music_category.append({'video_id': video_id, 'category_value': category_value})\n",
    "\n",
    "        videos.append({\n",
    "            'views': int(vid_views),\n",
    "            'url': yt_link,\n",
    "            'video_id': video_id,\n",
    "            'video_likes': int(vid_like_count),\n",
    "            'video_comments': int(vid_comment_count),\n",
    "            'video_category_id': int(category_id)\n",
    "        })\n",
    "\n",
    "# Convert the list of video details to a DataFrame\n",
    "df3 = pd.DataFrame(videos)\n",
    "\n",
    "# Merge the two DataFrames on 'video_id'\n",
    "df4 = df2.merge(df3, on='video_id')\n",
    "\n",
    "# Convert the list of music categories to a DataFrame\n",
    "df5 = pd.DataFrame(music_category)\n",
    "df_new=df4.merge(df5,on='video_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(440, 11)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['category_value']=df_new['category_value'].apply(','.join)\n",
    "df_new['publisheddate']= pd.to_datetime(df_new['publisheddate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new['tags']=df_new['videoOwnerChannelTitle']+df_new['category_value']\n",
    "#df_new['tags']=df_new['tags'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing some EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df_new.sort_values(by='views', ascending=False)\n",
    "\n",
    "# Plot a bar chart for the top 10 values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(df_sorted['video_title'].head(10), df_sorted['views'].head(10), color='skyblue')\n",
    "plt.xlabel('Total No of Views')\n",
    "plt.ylabel('Song Name')\n",
    "plt.title('Top 10 Songs based on views')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted2 = df_new.sort_values(by='video_likes', ascending=False)\n",
    "\n",
    "# Plot a bar chart for the top 10 values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(df_sorted2['video_title'].head(10), df_sorted2['video_likes'].head(10), color='skyblue')\n",
    "plt.xlabel('Total No of Likes')\n",
    "plt.ylabel('Sonog Name')\n",
    "plt.title('Top 10 Songs based on likes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted3 = df_new.sort_values(by='video_comments', ascending=False)\n",
    "\n",
    "# Plot a bar chart for the top 10 values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(df_sorted3['video_title'].head(10), df_sorted3['video_comments'].head(10), color='skyblue')\n",
    "plt.xlabel('Total No of Comments')\n",
    "plt.ylabel('Song Name')\n",
    "plt.title('Top 10 Songs based on Comments')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['publisheddate'] = df_new['publisheddate'].dt.strftime('%Y-%m-%d')\n",
    "df_new['year'] = pd.to_datetime(df_new['publisheddate']).dt.year\n",
    "grouped_df=df_new.groupby(df_new['year']).size()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(grouped_df, labels=grouped_df.index, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Records by Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_normalize=['views','video_likes','video_comments']\n",
    "data_to_normalize = df_new[columns_to_normalize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(data_to_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[columns_to_normalize]=scaler.transform(data_to_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''I created this rating formula where I am giving 50% weightage to views, \n",
    "30% weightage to likes and 20% weightage to comments to see top 50 songs in my playlist'''\n",
    "df_new['Rating']=df_new['views']*0.5+df_new['video_likes']*0.3+df_new['video_comments']*0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_songs=df_new.sort_values(by='Rating',ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_songs.to_csv('Popular_Songs.csv')\n",
    "ct=datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "s3=boto3.client('s3')\n",
    "\n",
    "\n",
    "\n",
    "bucket_name='bucket1swap'\n",
    "s3_folder='Snowflake_pipe/'\n",
    "file_name='Playlist_Songs_{}.csv'.format(ct)\n",
    "df_new.to_csv(file_name,index=False)\n",
    "s3.upload_file(file_name,bucket_name,s3_folder+file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
